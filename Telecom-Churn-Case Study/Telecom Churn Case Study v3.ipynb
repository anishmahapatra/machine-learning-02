{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/upGrad.png\" alt=\"upGrad\" align=\"Right\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/IIITB.jpeg\" alt=\"IITB\" align=\"Left\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Churn Case Study\n",
    "\n",
    "- <b>Authors:</b> Karthik Premanand, Anish Mahapatra\n",
    "- <b>Email-id:</b> karthikprem26@gmail.com, anishmahapatra01@gmail.com\n",
    "\n",
    "<i>Machine Learning II > Group Case Study 1 </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The telecommunications insdustry on average experiences a churn of 15-25%. It costs 5-10 times more to acquire a new customer than to retain an existing one. Customer retention has now become more important than customer acquisition.To reduce customer churn, telecom companies need to predict which customers are at a high risk of churn.\n",
    "\n",
    "The analysis involves customer-level data of a leading telecom firm, building predictive models to identify customers that are at a high risk of churn and to identify the main indicators of churn \n",
    "\n",
    "#### Methods of defining churn:\n",
    "- Postpaid: Disrectly inform the operator\n",
    "- Prepaid: Churn prediction is usually more critical (and non-trivial) for prepaid customers, and the term ‘churn’ should be defined carefully\n",
    "\n",
    "- Revenue-Based churn:  Customers who have not utilised any revenue-generating facilities such as mobile internet, outgoing calls, SMS etc. over a given period of time.\n",
    "\n",
    "The main shortcoming of this definition is that there are customers who only receive calls/SMSes from their wage-earning counterparts, i.e. they don’t generate revenue but use the services. For example, many users in rural areas only receive calls from their wage-earning siblings in urban areas.\n",
    "\n",
    "- Usage-based churn: Customers who have not done any usage, either incoming or outgoing - in terms of calls, internet etc. over a period of time.\n",
    "\n",
    "A potential shortcoming of this definition is that when the customer has stopped using the services for a while, it may be too late to take any corrective actions to retain them. For e.g., if you define churn based on a ‘two-months zero usage’ period, predicting churn could be useless since by that time the customer would have already switched to another operator.\n",
    "\n",
    "In this project, we will use the <b>usage-based</b> definition to define churn.\n",
    "    \n",
    "#### High-value Churn\n",
    "    \n",
    "In the Indian and the southeast Asian market, approximately 80% of revenue comes from the top 20% customers (called high-value customers). Thus, if we can reduce churn of the high-value customers, we will be able to reduce significant revenue leakage.\n",
    "\n",
    "In this project, you will define high-value customers and predict churn only on high-value customers.\n",
    "\n",
    "#### Understanding Customer Behaviour During Churn\n",
    "Customers usually do not decide to switch to another competitor instantly, but rather over a period of time (this is especially applicable to high-value customers). In churn prediction, we assume that there are three phases of customer lifecycle :\n",
    "\n",
    "- The ‘good’ phase: In this phase, the customer is happy with the service and behaves as usual.\n",
    "\n",
    "- The ‘action’ phase: The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a  competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘good’ months. Also, it is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)\n",
    "\n",
    "- The ‘churn’ phase: In this phase, the customer is said to have churned. You define churn based on this phase. Also, it is important to note that at the time of prediction (i.e. the action months), this data is not available to you for prediction. Thus, after tagging churn as 1/0 based on this phase, you discard all data corresponding to this phase.\n",
    "\n",
    "\n",
    "#### Data Preparation:\n",
    "1. Derive new features using business logic\n",
    "2. Filter high-value customers: Those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months (the good phase).\n",
    "After filtering the high-value customers, you should get about 29.9k rows.\n",
    "3. Tag churners and remove attributes of the churn phase: \n",
    "Now tag the churned customers (churn=1, else 0) based on the fourth month as follows: Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes you need to use to tag churners are:\n",
    "- total_ic_mou_9\n",
    "- total_og_mou_9\n",
    "- vol_2g_mb_9\n",
    "- vol_3g_mb_9\n",
    "\n",
    "After tagging churners, remove all the attributes corresponding to the churn phase (all attributes having ‘ _9’, etc. in their names).\n",
    "\n",
    "#### Modelling:\n",
    "Build models to predict churn. The predictive model that you’re going to build will serve two purposes:\n",
    "\n",
    "1. It will be used to predict whether a high-value customer will churn or not, in near future (i.e. churn phase). By knowing this, the company can take action steps such as providing special plans, discounts on recharge etc. (PCA + + Class-Imbalance + Classification)\n",
    "\n",
    "2. It will be used to identify important variables that are strong predictors of churn. These variables may also indicate why customers choose to switch to other networks.\n",
    "\n",
    "You can take the following suggestive steps to build the model:\n",
    "\n",
    "- Preprocess data (convert columns to appropriate formats, handle missing values, etc.)\n",
    "\n",
    "- Conduct appropriate exploratory analysis to extract useful insights (whether directly useful for business or for eventual modelling/feature engineering).\n",
    "\n",
    "- Derive new features.\n",
    "\n",
    "- Reduce the number of variables using PCA.\n",
    "\n",
    "- Train a variety of models, tune model hyperparameters, etc. (handle class imbalance using appropriate techniques).\n",
    "\n",
    "- Evaluate the models using appropriate evaluation metrics. Note that is is more important to identify churners than the non-churners accurately - choose an appropriate evaluation metric which reflects this business goal.\n",
    "\n",
    "- Finally, choose a model based on some evaluation metric.\n",
    "\n",
    "Build another model with the main objective of identifying important predictor attributes which help the business understand indicators of churn. A good choice to identify important variables is a logistic regression model or a model from the tree family. In case of logistic regression, make sure to handle multi-collinearity.\n",
    "\n",
    "After identifying important predictors, display them visually - you can use plots, summary tables etc. - whatever you think best conveys the importance of features.\n",
    "\n",
    "Finally, recommend strategies to manage customer churn based on your observations.\n",
    "\n",
    "### Goals of case Study:\n",
    "The business objective is to predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful.\n",
    "\n",
    "\n",
    "## Evaluation Rubric:\n",
    "- Data Quality Checks - missing value imputation, removing duplicate data, data redundancies\n",
    "- Data Quality Issues mentioned and clearly explained in comments\n",
    "- EDA using plots and summaries\n",
    "- Filter high-value customers\n",
    "- Feature engineering is done rigorusly and correctly\n",
    "\n",
    "#### 1. Data Cleaning\n",
    "- Handle actual missing values\n",
    "- Find percentage of missing values\n",
    "- Drop columns that have a high percentage of missing values\n",
    "- Drop columns that are highly skewed\n",
    "- Impute data wherever required\n",
    "- Check if target variable (Sales price) is normally distributed or not. If it is not normally distributed, perform transformation to make it normally distributed\n",
    "- Create dummy variables from categorical columns\n",
    "- Convert year column to find age by using Age = max(YearColumn) - year in the row\n",
    "- Scale the data\n",
    "\n",
    "#### 2. Modeling\n",
    "- PCA or some sort of dimensionality reduction technique is used, inclusing the data preparations required for it\n",
    "- Class imbalance is used for at least one of the techniques\n",
    "- Model hyperparameters are tuned using correct principles and the approach is explained clearly\n",
    "- A reasonable number and variety of different models are attempted and the best one is chosen based on key performance metrics\n",
    "- Model evaluation is conducted using an appropriate metric\n",
    "- Model evaluation results are at par with the best possible models on this data set\n",
    "\n",
    "#### 3.  Factors affecting Customer Churn and Business Recommendations\n",
    "- Important churn indicators are identified correctly\n",
    "- Clear actionable recommendations are provided based on supporting evidence\n",
    "\n",
    "#### Additional Notes:\n",
    "\n",
    "- Data cleaning using advanced techniques such as iterative imputer, KNN IMputer\n",
    "- Filter HVC. Use month 6 and month 7 data. Make 2 derived columns: \n",
    "\n",
    "total_rech_6 = total_calling_6 + total_data_6\n",
    "\n",
    "total_rech_7 = total_calling_7 + total_data_7\n",
    "\n",
    "avg_rech_6_7 = (total_rech_6 + total_rech_7) / 2\n",
    "\n",
    "Find 70th percentile value here and filter out > 70 percentile customers - The numbr of rows will be around 30k \n",
    "\n",
    "- Derive churn using month 9. Any customer that has calling = 0 and data = 0, then churn = 1\n",
    "\n",
    "calling_minutes_9 = calling_minutes_incoming_9 + calling_minutes_outgoing_9 is equal to zero AND\n",
    "\n",
    "data_usage = data_usage_2g_9 + data_usage_3g_9 is zero, Then the customer is churned\n",
    "\n",
    "Remove all the columns corresponding to month 9\n",
    "- EDA, Train-test split, Outlier Treatment\n",
    "- Class Imbalance Techniques - SMOTE, Weight of Class\n",
    "- Modelling:\n",
    "Interpretable Model: 1 technique -> Random Forest, Logistic Regression + RFE, \n",
    "Model with good prediction: With PCA -> At least 3 different techniques - Logistic Regression, Regularized regression, Decision Trees, Random Forest, SVM\n",
    "Perform hyper-parameter tuning\n",
    "- Look at sensitivity and make sure that Type 2 error is low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of the notebook.\n",
    "\n",
    "The purpose of the notebook as follows:\n",
    "1. Predict the churn of the customer in the 9th month\n",
    "2. Identify the factors that affect the churn of the customer\n",
    "\n",
    "Following are the steps to the followed to perform the analysis:\n",
    "\n",
    "- [#1 Data load, importing libraries & Sense Check of Data](#1)\n",
    "- [#2 Data Cleaning, Missing Value Treatment](#2)\n",
    "- [#3 Subsetting High-Value Customers using 70 percentile value](#3)\n",
    "- [#4 Feature Engineering and derived columns](#4)\n",
    "- [#5 Obtaining Customer Churn (1 - Churn, 0 - No Churn)](#5)\n",
    "- [#6 Exploratory Data Analysis (EDA)](#6)\n",
    "    - [#6.1 Univariate and Bivariate Analysis of Columns](#6.1)\n",
    "    - [#6.2 Outlier Analysis of the Data](#6.2)\n",
    "- [#7 Handling Class Imbalance in the data - SMOTE, Weight of Class](#7)\n",
    "- [#8 Modelling - Part 1: Obtaining best churn classification](#8)\n",
    "    - [#8.1 PCA](#8.1)\n",
    "        - [#8.1.1 Standardizing the data](#8.1)\n",
    "        - [#8.1.2 PCA on the dataset](#8.1)\n",
    "        - [#8.1.3 Scree Plot](#8.1)\n",
    "        - [#8.1.4 Plotting the Heatmap](#8.1)\n",
    "        - [#8.1.5 Hopkins Statistic](#8.1)\n",
    "        - [#8.1.6 Silhouette Score Plot](#8.1)\n",
    "        - [#8.1.7 Elbow Curve](#8.1)\n",
    "        - [#8.1.8 Test-Train Split](#8.1)\n",
    "    - [#8.2 Algorithm 1: Logistic Regression + RFE](#8.2)\n",
    "        - [#8.2.1 Recursive Feature Elimination](#8.2)\n",
    "        - [#8.2.2 Model Iterations](#8.2)\n",
    "        - [#8.2.3 Variance Inflation Factor (VIF)](#8.2)\n",
    "        - [#8.2.4 Residual Analysis of Train Data](#8.2)\n",
    "        - [#8.2.5 Making Predictions ](#8.2)\n",
    "        - [#8.2.6 Analysis of Results - Sensitivity and Type 2 Error](#8.2)\n",
    "    - [#8.3 Algorithm 2: Regularized Regression (Advanced Regression)](#8.3)\n",
    "        - [#8.3.1 Analysis of Feature to be predicted](#8.3.1)\n",
    "        - [#8.3.2 Ridge Regression](#8.3.2)\n",
    "        - [#8.3.3 Lasso Regression](#8.3.3)\n",
    "        - [#8.3.4 Analysis of Results - Sensitivity and Type 2 Error](#8.3.4)\n",
    "    - [#8.4 Algorithm 3: Decision Trees](#8.4)\n",
    "        - [#8.4.1 Decision Tree with default parameters ](#8.4)\n",
    "        - [#8.4.2 Plotting the Decision Tree ](#8.4)\n",
    "        - [#8.4.3 Hyperparameter Tuning](#8.4)\n",
    "            - [#8.4.3.1 Tuning max_depth](#8.4)\n",
    "            - [#8.4.3.2 Tuning min_samples_leaf ](#8.4)\n",
    "            - [#8.4.3.3 Tuning min_samples_split ](#8.4)\n",
    "         - [#8.4.4 Grid Search to find Optimal Hyperparameters](#8.4)\n",
    "         - [#8.4.5 Running the model with best parameters obtained from Grid Search](#8.4)\n",
    "         - [#8.4.6 Plotting the decision tree](#8.4)\n",
    "- [#9 Modelling - Part 2: Interpretable Results](#9)\n",
    "    - [#9.1 Logistic Regression + RFE](#9.1)\n",
    "        - [#9.2.1 Recursive Feature Elimination](#9.2)\n",
    "        - [#9.2.2 Model Iterations](#9.2)\n",
    "        - [#9.2.3 Variance Inflation Factor (VIF)](#9.2)\n",
    "        - [#9.2.4 Residual Analysis of Train Data](#9.2)\n",
    "        - [#9.2.5 Making Predictions ](#9.2)\n",
    "        - [#9.2.6 Analysis of Results - Sensitivity and Type 2 Error](#9.2)\n",
    "- [#10 Model Output Discussion](#10)\n",
    "- [#11 Outputs of the Analysis](#11)\n",
    "- [#12 Business Recommendations to reduce churn](#12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## #1 Data load, importing libraries & Sense Check of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## #2 Data Cleaning, Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## #3 Subsetting High-Value Customers using 70 percentile value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## #4 Feature Engineering and derived columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## #5 Obtaining Customer Churn (1 - Churn, 0 - No Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "## #6 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "### #6.1 Univariate and Bivariate Analysis of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2'></a>\n",
    "### #6.2 Outlier Analysis of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "## #7 Handling Class Imbalance in the data - SMOTE, Weight of Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8'></a>\n",
    "## #8 Modelling - Part 1: Obtaining best churn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8.1'></a>\n",
    "## #8.1 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.1 Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.2 PCA on the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.3 Scree Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.4 Plotting the Heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.5 Hopkins Statistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.6 Silhouette Score Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.7 Elbow Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.1.8 Test-Train Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8.2'></a>\n",
    "## #8.2 Algorithm 1: Logistic Regression + RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.2.1 Recursive Feature Elimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.2.2 Model Iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.2.3 Variance Inflation Factor (VIF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.2.4 Residual Analysis of Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.2.5 Making Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.2.6 Analysis of Results - Sensitivity and Type 2 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8.3'></a>\n",
    "## #8.3 Algorithm 2: Regularized Regression (Advanced Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.3.1 Analysis of Feature to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.3.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.3.3 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.3.4 Analysis of Results - Sensitivity and Type 2 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8.4'></a>\n",
    "## #8.4 Algorithm 3: Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.4.1 Decision Tree with default parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.4.2 Plotting the Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.4.3 Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #8.4.3.1 Tuning max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #8.4.3.2 Tuning min_samples_leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #8.4.3.3 Tuning min_samples_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.4.4 Grid Search to find Optimal Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.4.5 Running the model with best parameters obtained from Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.4.6 Plotting the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "## #9 Modelling - Part 2: Interpretable Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.1 Logistic Regression + RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.2.1 Recursive Feature Elimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.2.2 Model Iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.2.3 Variance Inflation Factor (VIF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.2.4 Residual Analysis of Train Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.2.5 Making Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.2.6 Analysis of Results - Sensitivity and Type 2 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='10'></a>\n",
    "## #10 Model Output Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11'></a>\n",
    "## #11 Outputs of the Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='12'></a>\n",
    "## #12 Business Recommendations to reduce churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
